# ============================================================================
# Global Configuration
# ============================================================================
# Configuration globale pour le framework TimeSeries Predict
# Paramètres partagés par toutes les entités

# ============================================================================
# MLflow Tracking
# ============================================================================

mlflow:
  # URI de tracking MLflow
  tracking_uri: "mlruns" # Local file store
  # Alternatives:
  #tracking_uri: "http://localhost:5000" # MLflow tracking server

  # Préfixe pour les noms d'expérimentations
  experiment_prefix: "CallFlox_"

  # Artifact storage
  # null = use default (serveur MLflow gère automatiquement)
  # En production, le serveur MLflow sera configuré avec le bon artifact_location
  artifact_location: null

  # Auto-logging
  autolog:
    enabled: false # Désactivé car on utilise sktime.utils.mlflow_sktime
    log_models: true
    log_input_examples: false
    log_model_signatures: true

  # Tags par défaut pour toutes les runs
  default_tags:
    framework: "sktime"
    project: "CallFlox"
    environment: "development" # development, staging, production

  # Paramètres de logging
  logging:
    log_system_metrics: true
    log_params: true
    log_metrics: true
    log_artifacts: true

  # Artifacts à sauvegarder automatiquement
  artifacts_to_log:
    - "predictions"
    - "models"
    - "plots"
    - "configs"
    - "reports"

# ============================================================================
# Logging
# ============================================================================

logging:
  # Niveau de logging
  level: "INFO" # DEBUG, INFO, WARNING, ERROR, CRITICAL

  # Format des logs
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

  # Format de la date dans les logs
  date_format: "%Y-%m-%d %H:%M:%S"

  # Fichier de log
  file:
    enabled: true
    path: "logs/timeseries_predict.log"
    max_bytes: 10485760 # 10 MB
    backup_count: 5
    encoding: "utf-8"

  # Logging console
  console:
    enabled: true
    colorize: true

  # Logging par module
  loggers:
    src.data_loading: "INFO"
    src.preprocessing: "INFO"
    src.training: "INFO"
    src.evaluation: "INFO"
    src.prediction: "INFO"
    src.tuning: "DEBUG" # Plus de détails pour le tuning
    mlflow: "WARNING"
    sktime: "WARNING"
    optuna: "INFO"

# ============================================================================
# Data Quality
# ============================================================================

data_quality:
  # Validation automatique
  validation:
    enabled: true

  # Checks à effectuer
  checks:
    - name: "no_missing_values"
      threshold: 0.05 # Max 5% de valeurs manquantes
      action: "warn" # "raise", "warn", "ignore"

    - name: "no_duplicates"
      action: "raise"

    - name: "date_continuity"
      max_gap_days: 7
      action: "warn"

    - name: "outliers_detection"
      method: "iqr" # "iqr", "zscore", "isolation_forest"
      threshold: 3.0
      action: "log"

  # Rapport de qualité
  report:
    enabled: true
    output_path: "outputs/data_quality/"

  # Profiling des données
  profiling:
    enabled: false
    library: "pandas_profiling" # "pandas_profiling", "sweetviz"
    output_format: "html"

# ============================================================================
# Execution Configuration
# ============================================================================

execution:
  # Parallélisation
  parallel:
    enabled: true # Activer l'exécution parallèle multi-entités
    n_jobs: -1 # Nombre de jobs parallèles (-1 = tous les CPU, 1 = séquentiel)
    backend: "loky" # Backend joblib: "loky", "threading", "multiprocessing"

  # Gestion d'erreurs
  fail_fast: false # Arrêter au premier échec
  skip_errors: true # Continuer même en cas d'erreur

# ============================================================================
# Output Configuration
# ============================================================================

output:
  # Dossiers de sortie pour les artifacts locaux
  # Ces chemins sont utilisés pour sauvegarder les fichiers en local
  # (en complément du tracking MLflow qui gère ses propres artifacts)
  directories:
    base: "outputs/" # Dossier racine
    predictions: "outputs/predictions/" # Prédictions production (CSV)
    models: "outputs/models/" # Modèles entraînés (PKL)
    plots: "outputs/plots/" # Graphiques et visualisations
    reports: "outputs/reports/" # Rapports d'évaluation
    logs: "outputs/logs/" # Logs d'exécution

  # Formats de sortie
  formats:
    predictions: "csv" # "csv", "parquet", "json"
    models: "pkl" # "pkl", "joblib"
    plots: "png" # "png", "pdf", "svg"
    reports: "html" # "html", "pdf", "markdown"

  # Naming convention
  naming:
    timestamp_format: "%Y%m%d_%H%M%S"
    include_entity_name: true
    include_model_name: true
    include_timestamp: true
